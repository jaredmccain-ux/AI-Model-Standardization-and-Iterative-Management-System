import torch
import torch.nn as nn
import torch.nn.functional as F
from ultralytics.models.yolo.detect.train import DetectionTrainer
from ultralytics.utils import loss
from ultralytics.utils.ops import xywh2xyxy, non_max_suppression
from pathlib import Path
import random
import numpy as np
from PIL import Image
import torchvision.transforms as T

class DistillationTrainer(DetectionTrainer):
    """
    ä¸€ä¸ªé›†æˆäº†çŸ¥è¯†è’¸é¦ã€æ—§æ ·æœ¬å›æ”¾ã€ä¼ªæ ‡ç­¾ç”Ÿæˆå’Œä¸€è‡´æ€§æ­£åˆ™åŒ–çš„YOLOv8æ£€æµ‹è®­ç»ƒå™¨ã€‚
    """
    def __init__(self, *args, **kwargs):
        overrides = kwargs.get('overrides', {})
        self.teacher_model_arg = overrides.pop('teacher_model', None)
        self.distill_cls_weight = overrides.pop('distill_cls_weight', 1.0)
        self.distill_reg_weight = overrides.pop('distill_reg_weight', 2.0)
        self.distill_feat_weight = overrides.pop('distill_feat_weight', 5.0)
        self.temperature = overrides.pop('temperature', 2.0)
        self.class_weights = overrides.pop('class_weights', {})
        self.distill_bg_weight = overrides.pop('distill_bg_weight', 0.05)
        self.custom_names = overrides.pop('names', None)
        self.new_class_ids = overrides.pop('new_class_ids', [])
        
        self.old_data_yaml = overrides.pop('old_data_yaml', None)
        self.replay_ratio = overrides.pop('replay_ratio', 0.3)
        self.replay_distill_boost = overrides.pop('replay_distill_boost', 2.0)
        self.max_replay_samples = overrides.pop('max_replay_samples', 500)

        # æ–°å¢ï¼šä¼ªæ ‡ç­¾å’Œä¸€è‡´æ€§å‚æ•°
        self.pseudo_conf_threshold = overrides.pop('pseudo_conf_threshold', 0.7)
        self.enable_consistency = overrides.pop('enable_consistency', False)
        self.consistency_weight = overrides.pop('consistency_weight', 1.0)

        if self.teacher_model_arg is None:
            raise ValueError("DistillationTrainer requires a 'teacher_model' argument.")

        super().__init__(*args, **kwargs)

        self.teacher_model = self.teacher_model_arg
        self.distill_cls_loss = nn.KLDivLoss(reduction='none')
        self.feat_loss = nn.MSELoss()
        
        self.replay_buffer = []
        self.old_class_ids = []

        # å®šä¹‰å¼ºå¢å¼ºå˜æ¢ (ä»…å…‰åº¦å˜æ¢ï¼Œä¸æ”¹å˜å‡ ä½•åæ ‡)
        self.strong_aug = T.Compose([
            T.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),
            T.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),
        ])

    def _setup_train(self, world_size):
        super()._setup_train(world_size)

        if self.custom_names:
            print("\nâœ… åœ¨è®­ç»ƒå¼€å§‹å‰ï¼Œæ­£åœ¨åŒæ­¥ç±»åˆ«åç§°...")
            names_dict = {i: name for i, name in enumerate(self.custom_names)}
            self.data['names'] = names_dict
            self.model.names = names_dict
            if self.validator:
                self.validator.names = names_dict

        self.teacher_model.to(self.device)
        self.teacher_model.eval()
        for param in self.teacher_model.parameters():
            param.requires_grad = False
        
        self.num_old_classes = self.teacher_model.nc
        student_nc = self.data.get('nc', 'æœªçŸ¥')
        self.old_class_ids = list(range(self.num_old_classes))
        
        print("\nâœ… çŸ¥è¯†è’¸é¦è®­ç»ƒå™¨å·²æˆåŠŸè®¾ç½®ã€‚")
        print(f"   - æ•™å¸ˆ/å­¦ç”Ÿç±»åˆ«æ•°: {self.num_old_classes} -> {student_nc}")
        print(f"   - æ–°ç±»åˆ«ID: {self.new_class_ids}")
        
        if self.old_data_yaml:
            self._load_replay_buffer()
        else:
            print("   âš ï¸  æœªæä¾›æ—§æ•°æ®é›†è·¯å¾„ï¼Œæ—§æ ·æœ¬å›æ”¾åŠŸèƒ½å·²ç¦ç”¨")

    def _load_replay_buffer(self):
        print(f"\nğŸ“¦ æ­£åœ¨æ„å»ºæ—§æ ·æœ¬å›æ”¾ç¼“å†²åŒº...")
        print(f"   - æ—§æ•°æ®é›†é…ç½®: {self.old_data_yaml}")
        print(f"   - å›æ”¾æ¯”ä¾‹: {self.replay_ratio:.1%}")
        print(f"   - æœ€å¤§æ ·æœ¬æ•°: {self.max_replay_samples}")
        
        try:
            import yaml
            old_data_path = Path(self.old_data_yaml)
            if not old_data_path.exists():
                print(f"   âŒ æ—§æ•°æ®é›†é…ç½®æ–‡ä»¶ä¸å­˜åœ¨")
                return
            
            with old_data_path.open('r', encoding='utf-8') as f:
                old_data_cfg = yaml.safe_load(f)
            
            old_base_path = Path(old_data_cfg.get('path', old_data_path.parent))
            old_train_path = old_data_cfg.get('train', 'images/train')
            
            if Path(old_train_path).is_absolute():
                old_img_dir = Path(old_train_path)
            else:
                old_img_dir = (old_base_path / old_train_path).resolve()
            
            old_label_dir = old_img_dir.parent.parent / 'labels' / old_img_dir.name
            if not old_label_dir.exists():
                old_label_dir = Path(str(old_img_dir).replace('images', 'labels'))
            
            if not old_label_dir.exists():
                print(f"   âŒ æœªæ‰¾åˆ°æ—§æ•°æ®é›†çš„æ ‡ç­¾ç›®å½•")
                return
            
            image_files = list(old_img_dir.glob('*.jpg')) + list(old_img_dir.glob('*.png'))
            valid_samples = []
            
            for img_path in image_files:
                label_path = old_label_dir / (img_path.stem + '.txt')
                if label_path.exists():
                    valid_samples.append({
                        'img_path': str(img_path),
                        'label_path': str(label_path)
                    })
            
            if len(valid_samples) > self.max_replay_samples:
                self.replay_buffer = random.sample(valid_samples, self.max_replay_samples)
            else:
                self.replay_buffer = valid_samples
            
            print(f"   âœ… æˆåŠŸåŠ è½½ {len(self.replay_buffer)} ä¸ªæ—§æ ·æœ¬åˆ°å›æ”¾ç¼“å†²åŒº")
            
        except Exception as e:
            print(f"   âŒ åŠ è½½æ—§æ ·æœ¬å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

    def preprocess_batch(self, batch):
        """
        é‡å†™batché¢„å¤„ç†ï¼Œæ··å…¥æ—§æ ·æœ¬ã€‚
        æ ¸å¿ƒä¿®å¤ï¼šç¡®ä¿æ‰€æœ‰å¼ é‡çš„ç»´åº¦æ­£ç¡®åŒ¹é…ã€‚
        """
        batch = super().preprocess_batch(batch)
        
        # ç¡®ä¿batchä¸­çš„æ ¸å¿ƒå¼ é‡éƒ½åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
        batch['cls'] = batch['cls'].to(self.device)
        batch['bboxes'] = batch['bboxes'].to(self.device)
        batch['batch_idx'] = batch['batch_idx'].to(self.device)
        
        if not self.replay_buffer or self.replay_ratio <= 0:
            batch['is_replay'] = torch.zeros(batch['img'].shape[0], dtype=torch.bool, device=self.device)
            return batch
        
        batch_size = batch['img'].shape[0]
        num_replay = int(batch_size * self.replay_ratio)
        
        if num_replay == 0:
            batch['is_replay'] = torch.zeros(batch_size, dtype=torch.bool, device=self.device)
            return batch
        
        replace_indices = random.sample(range(batch_size), min(num_replay, batch_size))
        is_replay = torch.zeros(batch_size, dtype=torch.bool, device=self.device)
        is_replay[replace_indices] = True
        
        for idx in replace_indices:
            old_sample = random.choice(self.replay_buffer)
            
            # åŠ è½½æ—§å›¾ç‰‡
            img = Image.open(old_sample['img_path']).convert('RGB')
            img_size = batch['img'].shape[2]
            img = img.resize((img_size, img_size))
            img = np.array(img).transpose(2, 0, 1)
            img = torch.from_numpy(img).float() / 255.0
            batch['img'][idx] = img.to(self.device)
            
            # åŠ è½½æ—§æ ‡ç­¾
            labels = []
            with open(old_sample['label_path'], 'r') as f:
                for line in f:
                    parts = line.strip().split()
                    if len(parts) >= 5:
                        cls_id = int(parts[0])
                        bbox = [float(x) for x in parts[1:5]]
                        labels.append([cls_id] + bbox)
            
            if labels:
                labels_tensor = torch.tensor(labels, dtype=torch.float32, device=self.device)
                
                # è®¡ç®—mask
                mask = (batch['batch_idx'] == idx).squeeze()
                
                if mask.any():
                    # --- å…³é”®ä¿®å¤ï¼šç¡®ä¿ç»´åº¦åŒ¹é… ---
                    keep_mask = ~mask
                    
                    # å¤„ç† cls
                    if batch['cls'].dim() == 1:
                        new_cls = torch.cat([batch['cls'][keep_mask], labels_tensor[:, 0]], dim=0)
                    else:
                        new_cls = torch.cat([batch['cls'][keep_mask], labels_tensor[:, 0:1]], dim=0)
                    
                    new_bboxes = torch.cat([batch['bboxes'][keep_mask], labels_tensor[:, 1:5]], dim=0)
                    
                    # å¤„ç† batch_idx
                    new_batch_idx_vals = torch.full((labels_tensor.shape[0],), idx, 
                                                    dtype=batch['batch_idx'].dtype, device=self.device)
                    
                    if batch['batch_idx'].dim() == 1:
                        new_batch_idx = torch.cat([batch['batch_idx'][keep_mask], new_batch_idx_vals], dim=0)
                    else:
                        new_batch_idx = torch.cat([batch['batch_idx'][keep_mask], new_batch_idx_vals.unsqueeze(1)], dim=0)
                    
                    batch['cls'] = new_cls
                    batch['bboxes'] = new_bboxes
                    batch['batch_idx'] = new_batch_idx
                else:
                    # å¦‚æœè¯¥ç´¢å¼•åŸæœ¬æ²¡æœ‰æ ‡ç­¾ï¼Œç›´æ¥æ·»åŠ 
                    if batch['cls'].dim() == 1:
                        batch['cls'] = torch.cat([batch['cls'], labels_tensor[:, 0]], dim=0)
                    else:
                        batch['cls'] = torch.cat([batch['cls'], labels_tensor[:, 0:1]], dim=0)
                    
                    batch['bboxes'] = torch.cat([batch['bboxes'], labels_tensor[:, 1:5]], dim=0)
                    
                    new_batch_idx_vals = torch.full((labels_tensor.shape[0],), idx,
                                                    dtype=batch['batch_idx'].dtype, device=self.device)
                    
                    if batch['batch_idx'].dim() == 1:
                        batch['batch_idx'] = torch.cat([batch['batch_idx'], new_batch_idx_vals], dim=0)
                    else:
                        batch['batch_idx'] = torch.cat([batch['batch_idx'], new_batch_idx_vals.unsqueeze(1)], dim=0)
        
        batch['is_replay'] = is_replay

        # --- æ–°å¢ï¼šä¸€è‡´æ€§è®­ç»ƒçš„å¼ºå¼±å¢å¼ºå¤„ç† ---
        if self.enable_consistency:
            # ä¿å­˜å¼±å¢å¼ºè§†å›¾ä¾›æ•™å¸ˆæ¨¡å‹ä½¿ç”¨
            batch['img_weak'] = batch['img'].clone()
            
            # å¯¹å­¦ç”Ÿæ¨¡å‹çš„è¾“å…¥åº”ç”¨å¼ºå¢å¼º
            # æ³¨æ„ï¼šbatch['img'] æ˜¯ (B, 3, H, W)ï¼Œå€¼åŸŸ [0, 1]
            try:
                # åº”ç”¨å¼ºå¢å¼º
                batch['img'] = self.strong_aug(batch['img'])
            except Exception as e:
                # å¶å°”å¯èƒ½ä¼šå› ä¸ºè®¾å¤‡é—®é¢˜å¤±è´¥ï¼Œæ•è·å¼‚å¸¸
                pass

        return batch

    def _add_pseudo_labels(self, batch, teacher_preds):
        """åˆ©ç”¨æ•™å¸ˆæ¨¡å‹ç”Ÿæˆä¼ªæ ‡ç­¾å¹¶åˆå¹¶åˆ°Batchä¸­"""
        # teacher_preds: (B, 4+NC, Anchors) -> (B, Anchors, 4+NC)
        preds_for_nms = teacher_preds.permute(0, 2, 1)
        
        # ä»…å¯¹æ—§ç±»åˆ«ç”Ÿæˆä¼ªæ ‡ç­¾
        pseudo_results = non_max_suppression(
            preds_for_nms,
            conf_thres=self.pseudo_conf_threshold,
            iou_thres=0.7,
            classes=self.old_class_ids,
            multi_label=True
        )
        
        new_cls_list = []
        new_bboxes_list = []
        new_batch_idx_list = []
        
        h, w = batch['img'].shape[2:]
        
        for i, det in enumerate(pseudo_results):
            if len(det) == 0: continue
            
            # det: (n, 6) [x1, y1, x2, y2, conf, cls]
            # è½¬æ¢åæ ‡ xyxy -> xywh (normalized)
            bboxes = det[:, :4].clone()
            xywh = torch.zeros_like(bboxes)
            xywh[:, 0] = (bboxes[:, 0] + bboxes[:, 2]) / 2 / w
            xywh[:, 1] = (bboxes[:, 1] + bboxes[:, 3]) / 2 / h
            xywh[:, 2] = (bboxes[:, 2] - bboxes[:, 0]) / w
            xywh[:, 3] = (bboxes[:, 3] - bboxes[:, 1]) / h
            
            cls = det[:, 5:6]
            
            new_cls_list.append(cls)
            new_bboxes_list.append(xywh)
            # batch_idx éœ€è¦ä¸ç°æœ‰æ ¼å¼åŒ¹é…
            new_batch_idx_list.append(torch.full((len(det), 1), i, device=self.device))
            
        if new_cls_list:
            p_cls = torch.cat(new_cls_list, dim=0)
            p_bboxes = torch.cat(new_bboxes_list, dim=0)
            p_bidx = torch.cat(new_batch_idx_list, dim=0)
            
            # æ‹¼æ¥åˆ° batch
            if batch['cls'].dim() == 1:
                 batch['cls'] = torch.cat([batch['cls'], p_cls.squeeze(-1)], dim=0)
            else:
                 batch['cls'] = torch.cat([batch['cls'], p_cls], dim=0)
                 
            batch['bboxes'] = torch.cat([batch['bboxes'], p_bboxes], dim=0)
            
            if batch['batch_idx'].dim() == 1:
                batch['batch_idx'] = torch.cat([batch['batch_idx'], p_bidx.squeeze(-1)], dim=0)
            else:
                batch['batch_idx'] = torch.cat([batch['batch_idx'], p_bidx], dim=0)

    def get_loss(self, preds, batch):
        """è®¡ç®—æ€»æŸå¤±ï¼ŒåŒ…æ‹¬æ ‡å‡†æ£€æµ‹æŸå¤±ã€çŸ¥è¯†è’¸é¦æŸå¤±ã€ä¼ªæ ‡ç­¾æŸå¤±å’Œä¸€è‡´æ€§æŸå¤±ã€‚"""
        student_nc = self.data['nc']

        # 1. å‡†å¤‡æ•™å¸ˆæ¨¡å‹è¾“å…¥ (å¦‚æœå¯ç”¨ä¸€è‡´æ€§ï¼Œä½¿ç”¨å¼±å¢å¼ºè§†å›¾)
        teacher_img = batch.get('img_weak', batch['img']) if self.enable_consistency else batch['img']
        
        with torch.no_grad():
            teacher_output = self.teacher_model(teacher_img)
            teacher_preds, teacher_feats = teacher_output[0], teacher_output[1]

        # 2. ç”Ÿæˆä¼ªæ ‡ç­¾å¹¶åˆå¹¶åˆ° Batch (å¦‚æœå¯ç”¨ä¸”é˜ˆå€¼æœ‰æ•ˆ)
        if self.pseudo_conf_threshold > 0 and self.pseudo_conf_threshold < 1.0:
            self._add_pseudo_labels(batch, teacher_preds)

        if not hasattr(self, 'iou_loss'):
            self.iou_loss = loss.v8DetectionLoss(self.model).iou_loss

        # 3. è®¡ç®—æ ‡å‡†æŸå¤± (æ­¤æ—¶ batch å¯èƒ½å·²åŒ…å«ä¼ªæ ‡ç­¾)
        loss_gt, loss_items = super().get_loss(preds, batch)
        
        student_preds, student_feats = preds[0], preds[1]
        
        # ç‰¹å¾è’¸é¦æŸå¤±
        loss_distill_feat = 0.0
        if student_feats and teacher_feats:
            for feat_s, feat_t in zip(student_feats, teacher_feats):
                loss_distill_feat += self.feat_loss(feat_s, feat_t)

        loss_distill_cls = 0.0
        loss_distill_reg = 0.0
        
        target_scores, _, _, _, _, fg_mask_gt = self.criterion.assigner(
            student_preds, (batch['cls'].view(-1, 1), batch['bboxes'].view(-1, 4)), 
            batch['batch_idx'].view(-1, 1), self.model
        )
        
        new_class_mask_gt = torch.zeros_like(fg_mask_gt)
        if fg_mask_gt.any():
            gt_cls_in_pred_space = target_scores[fg_mask_gt].argmax(-1)
            is_new_class = torch.isin(gt_cls_in_pred_space, torch.tensor(self.new_class_ids, device=self.device))
            new_class_mask_gt[fg_mask_gt] = is_new_class

        _, anchor_points, stride_tensor = self.model.head.make_anchors(student_preds, self.model.head.stride, 0.5)
        is_replay = batch.get('is_replay', torch.zeros(batch['img'].shape[0], dtype=torch.bool, device=self.device))

        for i, (pred_s, pred_t_raw) in enumerate(zip(student_preds, teacher_preds)):
            with torch.no_grad():
                pred_t_aligned = torch.zeros_like(pred_s)
                pred_t_aligned[..., :4] = pred_t_raw[..., :4]
                pred_t_aligned[..., 4:4 + self.num_old_classes] = pred_t_raw[..., 4:]
                
                pred_t_cls = pred_t_aligned[..., 4:].view(-1, student_nc)
                teacher_probs = F.softmax(pred_t_cls / self.temperature, dim=1)
                teacher_max_probs, teacher_max_ids = torch.max(pred_t_cls.softmax(dim=1), dim=1)
                fg_mask_teacher = teacher_max_probs > self.args.conf
            
            distill_mask = ~new_class_mask_gt
            batch_indices = torch.arange(pred_s.shape[0], device=self.device).view(-1, 1, 1).expand_as(pred_s[..., 0])
            is_replay_expanded = is_replay[batch_indices.view(-1)].view_as(fg_mask_teacher)
            
            fg_distill_mask = fg_mask_teacher & distill_mask
            bg_distill_mask = ~fg_mask_teacher & distill_mask

            loss_fg = 0.0
            if fg_distill_mask.any():
                weights = torch.ones_like(teacher_max_ids[fg_distill_mask], dtype=torch.float32)
                replay_boost = torch.where(
                    is_replay_expanded[fg_distill_mask],
                    torch.tensor(self.replay_distill_boost, device=self.device),
                    torch.tensor(1.0, device=self.device)
                )
                
                if self.class_weights:
                    for class_id, weight in self.class_weights.items():
                        weights[teacher_max_ids[fg_distill_mask] == class_id] = weight
                
                weights *= replay_boost
                cls_s_fg = F.log_softmax(pred_s[..., 4:].view(-1, student_nc)[fg_distill_mask] / self.temperature, dim=1)
                kl_div_fg = self.distill_cls_loss(cls_s_fg, teacher_probs[fg_distill_mask]).sum(dim=1)
                loss_fg = (kl_div_fg * weights).mean()

            loss_bg = 0.0
            if bg_distill_mask.any():
                replay_boost_bg = torch.where(
                    is_replay_expanded[bg_distill_mask],
                    torch.tensor(self.replay_distill_boost * 0.5, device=self.device),
                    torch.tensor(1.0, device=self.device)
                )
                cls_s_bg = F.log_softmax(pred_s[..., 4:].view(-1, student_nc)[bg_distill_mask] / self.temperature, dim=1)
                kl_div_bg = self.distill_cls_loss(cls_s_bg, teacher_probs[bg_distill_mask]).sum(dim=1)
                loss_bg = (kl_div_bg * replay_boost_bg).mean()

            loss_distill_cls += (loss_fg + self.distill_bg_weight * loss_bg) * (self.temperature ** 2)

            if fg_distill_mask.any():
                box_s = self.decode_bboxes(pred_s[..., :4], anchor_points[i], stride_tensor[i])
                box_t = self.decode_bboxes(pred_t_aligned[..., :4], anchor_points[i], stride_tensor[i])
                replay_boost_reg = torch.where(
                    is_replay_expanded[fg_distill_mask],
                    torch.tensor(self.replay_distill_boost, device=self.device),
                    torch.tensor(1.0, device=self.device)
                )
                iou = self.iou_loss(box_s[fg_distill_mask], box_t[fg_distill_mask])
                loss_distill_reg += (iou * replay_boost_reg).mean()

        # åº”ç”¨ä¸€è‡´æ€§æƒé‡ (å¦‚æœæœ‰)
        consistency_factor = self.consistency_weight if self.enable_consistency else 1.0
        
        total_distill_loss = (self.distill_cls_weight * loss_distill_cls +
                              self.distill_reg_weight * loss_distill_reg +
                              self.distill_feat_weight * loss_distill_feat) * consistency_factor
        
        total_loss = loss_gt + total_distill_loss
        new_loss_items = torch.tensor([loss_distill_cls, loss_distill_reg, loss_distill_feat], device=self.device)
        loss_items = torch.cat((loss_items, new_loss_items))
        
        return total_loss, loss_items

    def decode_bboxes(self, pred_dist, anchor_points, stride):
        box_preds = self.model.head.dfl(pred_dist)
        box_preds = box_preds * stride
        return xywh2xyxy(torch.cat((anchor_points - box_preds[..., :2], anchor_points + box_preds[..., 2:]), -1))

